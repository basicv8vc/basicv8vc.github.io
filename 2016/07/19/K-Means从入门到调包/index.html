<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>K-Means从入门到调包 | Yet Another Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">K-Means从入门到调包</h1><a id="logo" href="/.">Yet Another Blog</a><p class="description">Something on Programming.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">K-Means从入门到调包</h1><div class="post-meta">Jul 19, 2016<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-disqus-identifier="2016/07/19/K-Means从入门到调包/" href="/2016/07/19/K-Means从入门到调包/#disqus_thread" class="disqus-comment-count"></a><div class="post-content"><p>在做数据挖掘项目时，拿到数据，首先要分析问题和观察数据，我在“观察数据”这一阶段主要是看看有没有直观的数据规律以及异常点，对于那些特征维度较低的数据，比如仅仅2维，我选择画散点图观察，高纬度数据可以用t-SNE降维后再画图。除了可视化，聚类算法也是找到异常点的常用手段之一。</p>
<p>这篇博客介绍一种最基本的聚类算法：K-Means。</p>
<h2 id="算法描述与EM"><a href="#算法描述与EM" class="headerlink" title="算法描述与EM"></a>算法描述与EM</h2><p>聚类算法的作用是将数据集自动划分为多个不同的集合。 K-Means算法是典型的无监督算法，对于数据集$D$, 我们设定参数k(k个集合)，她就能自动地学习出k个类别，简单又神奇。那么K-Means是如何学习到这k个集合呢？专业一点说就是，K-Means的目标函数是啥？如何优化她的目标函数？先回答第一个问题，下面就是K-Means的目标函数：</p>
<p><img src="https://ooo.0o0.ooo/2016/07/18/578d9ed1157e4.png" alt=""></p>
<p>物理意义：我们希望找到的k个集合，每个集合内的点都距离此集合内平均值点最近(每个集合中的点都紧密团结在一起)。</p>
<p>知道了目标函数，下一步就要考虑如何求解，最常见的求解方法是Lloyd算法，也就是使用EM算法，注意，Lloyd算法得到的结果是局部极小值而不是全局最小值哦。</p>
<p>EM算法求解步骤很简单，总共分三步：</p>
<ul>
<li>将所有数据点都分配到某个集合 -&gt; 计算每个点到集合平均值点的欧氏距离</li>
<li>计算每个集合内点的平均值 -&gt; 计算每个特征的平均值</li>
<li>重复上面两步直到局部收敛 -&gt; 前后两次迭代的集合结果相同</li>
</ul>
<p>上面的三步概括起来就是 E-&gt;M-&gt;E-&gt;M-&gt;………..</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">import numpy as np</div><div class="line">from collections import defaultdict</div><div class="line">from random import uniform</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeans</span>(<span class="title">object</span>):</span></div><div class="line">    <span class="string">""</span><span class="string">"</span></div><div class="line">    kmeans 聚类算算</div><div class="line">    "<span class="string">""</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span>:</div><div class="line">        pass</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cluster</span><span class="params">(<span class="keyword">self</span>, X, k, initializer=<span class="string">"random"</span>)</span></span>:</div><div class="line">        <span class="keyword">self</span>.X = X</div><div class="line">        <span class="keyword">self</span>.k = k</div><div class="line">        <span class="keyword">self</span>.centers = defaultdict(list)</div><div class="line">        <span class="keyword">self</span>.assignment = np.zeros(<span class="keyword">self</span>.X.shape[<span class="number">0</span>]) <span class="comment">#记录每个样本属于哪个中心点</span></div><div class="line">        <span class="keyword">if</span> initializer == <span class="string">"random"</span>:</div><div class="line">            <span class="keyword">self</span>._initialize() <span class="comment">#初始化得到k个点</span></div><div class="line">        elif initializer == <span class="string">"kmeans++"</span>:</div><div class="line">            <span class="keyword">self</span>._carefulSeed()</div><div class="line">        <span class="symbol">else:</span></div><div class="line">            raise ValueError(<span class="string">'initializer error!'</span>)</div><div class="line">        <span class="keyword">self</span>._assign() <span class="comment">#将数据集中每个样本分配给最近的中心点</span></div><div class="line">        <span class="keyword">self</span>.next_centers = None</div><div class="line">        <span class="keyword">while</span> <span class="keyword">self</span>.centers != <span class="keyword">self</span>.<span class="symbol">next_centers:</span></div><div class="line">            <span class="keyword">self</span>.next_centers = <span class="keyword">self</span>.centers</div><div class="line">            <span class="keyword">self</span>._getcenters()</div><div class="line">            <span class="keyword">self</span>._assign()</div><div class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.assignment</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_carefulSeed</span><span class="params">(<span class="keyword">self</span>)</span></span>:</div><div class="line">        <span class="string">""</span><span class="string">"</span></div><div class="line">        kmeans++</div><div class="line">        1、从输入的数据点集合（要求有k个聚类）中随机选择一个点作为第一个聚类中心</div><div class="line">        2、对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)</div><div class="line">        3、选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大</div><div class="line">        4、重复2和3直到k个聚类中心被选出来</div><div class="line">        "<span class="string">""</span></div><div class="line">        from random import randint</div><div class="line">        index = randint(<span class="number">0</span>, <span class="keyword">self</span>.X.shape[<span class="number">0</span>]-<span class="number">1</span>)</div><div class="line">        <span class="keyword">self</span>.centers[<span class="number">0</span>] = <span class="keyword">self</span>.X[index]</div><div class="line">        indexs = &#123;<span class="symbol">index:</span><span class="number">1</span>&#125; <span class="comment">#记录中心点是X中的第几个点(index), 以避免选择相同的点作为类中心</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.k)[<span class="number">1</span><span class="symbol">:</span>]:</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize</span><span class="params">(<span class="keyword">self</span>)</span></span>:</div><div class="line">        <span class="string">""</span><span class="string">"</span></div><div class="line">        初始化，即初始化k个中心点和每个样本属于哪个中心点</div><div class="line">        这k个样本点是随机产生的</div><div class="line">        "<span class="string">""</span></div><div class="line">        feature_min_max = defaultdict(list) <span class="comment">#保存每个特征值的最小值和最大值</span></div><div class="line">        feature_dimensions = <span class="keyword">self</span>.X.shape[<span class="number">1</span>]</div><div class="line">        get_min_max = lambda x, <span class="symbol">y:</span> (x,y) <span class="keyword">if</span> x&lt;y <span class="keyword">else</span> (y,x)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(feature_dimensions):</div><div class="line">            i_min, i_max = get_min_max(<span class="keyword">self</span>.X[<span class="number">0</span>][i], <span class="keyword">self</span>.X[<span class="number">1</span>][i])</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="keyword">self</span>.X.shape[<span class="number">0</span>])[<span class="number">2</span><span class="symbol">:-</span><span class="number">1</span><span class="symbol">:</span><span class="number">2</span>]:</div><div class="line">                tmp_min, tmp_max = get_min_max(<span class="keyword">self</span>.X[j][i], <span class="keyword">self</span>.X[j+<span class="number">1</span>][i])<span class="comment">#self.X[j+1][i], self.X[j][i] if self.X[j][i] &gt; self.X[j+1][i] else self.X[j][i], self.X[j+1][i]</span></div><div class="line">                <span class="keyword">if</span> tmp_min &lt; <span class="symbol">i_min:</span></div><div class="line">                    i_min = tmp_min</div><div class="line">                <span class="keyword">if</span> tmp_max &gt; <span class="symbol">i_max:</span></div><div class="line">                    i_max = tmp_max</div><div class="line">            tmp_min, tmp_max = get_min_max(<span class="keyword">self</span>.X[-<span class="number">1</span>][i], <span class="keyword">self</span>.X[-<span class="number">2</span>][i])<span class="comment">#self.X[-1][i], self.X[-2][i] if self.X[-2][i] &gt; self.X[-1][i] else self.X[-2][i], self.X[-1][i]</span></div><div class="line">            i_min = tmp_min <span class="keyword">if</span> tmp_min &lt; i_min <span class="keyword">else</span> i_min</div><div class="line">            i_max = tmp_max <span class="keyword">if</span> tmp_max &gt; i_max <span class="keyword">else</span> i_max</div><div class="line">            feature_min_max[i] = [i_min, i_max]</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="keyword">self</span>.k):</div><div class="line">            this_k = []</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(feature_dimensions):</div><div class="line">                value = uniform(feature_min_max[j][<span class="number">0</span>], feature_min_max[j][<span class="number">1</span>])</div><div class="line">                this_k.append(value)</div><div class="line">            <span class="keyword">self</span>.centers[i] = this_k</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_distance</span><span class="params">(<span class="keyword">self</span>, point1, point2)</span></span>:</div><div class="line">        <span class="string">""</span><span class="string">"</span></div><div class="line">        计算点point1 和 point2 之间的欧氏距离</div><div class="line">        "<span class="string">""</span></div><div class="line">        dd = <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(point1)):</div><div class="line">            dd += (point1[i] - point2[i]) ** <span class="number">2</span></div><div class="line">        <span class="keyword">return</span> np.sqrt(dd)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_assign</span><span class="params">(<span class="keyword">self</span>)</span></span>:</div><div class="line"></div><div class="line">        feature_dimensions = <span class="keyword">self</span>.X.shape[<span class="number">1</span>]</div><div class="line"></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="keyword">self</span>.X.shape[<span class="number">0</span>]):</div><div class="line">            min_distance = float(<span class="string">"inf"</span>)</div><div class="line">            current_assignment = <span class="keyword">self</span>.k</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="keyword">self</span>.k):</div><div class="line">                tmp_d = <span class="keyword">self</span>._distance(<span class="keyword">self</span>.X[i], <span class="keyword">self</span>.centers[j])</div><div class="line">                <span class="keyword">if</span> tmp_d &lt; <span class="symbol">min_distance:</span></div><div class="line">                    min_distance = tmp_d</div><div class="line">                    current_assignment = j</div><div class="line">            <span class="keyword">self</span>.assignment[i] = current_assignment</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_getcenters</span><span class="params">(<span class="keyword">self</span>)</span></span>:</div><div class="line">        <span class="string">""</span><span class="string">"</span></div><div class="line">        计算每个中心点的平均值，作为新的中心点</div><div class="line">        "<span class="string">""</span></div><div class="line">        cluster_numbers = defaultdict(int) <span class="comment">#记录每个分类的样本数目</span></div><div class="line">        cluster_sum = np.zeros((<span class="keyword">self</span>.k, len(<span class="keyword">self</span>.X[<span class="number">0</span>]))) <span class="comment">#记录每个分类的所有样本相加之和</span></div><div class="line">        <span class="keyword">for</span> index, center <span class="keyword">in</span> enumerate(<span class="keyword">self</span>.assignment):</div><div class="line">            cluster_numbers[center] = cluster_numbers.get(center, <span class="number">0</span>) + <span class="number">1</span></div><div class="line">            cluster_sum[center] += <span class="keyword">self</span>.X[index]</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="keyword">self</span>.k):</div><div class="line">            <span class="keyword">self</span>.centers[i] = list(cluster_sum[i]/float(cluster_numbers[i]))</div></pre></td></tr></table></figure>
<!-- ## 初始化

使用 kmeans++初始化


## 梯度下降求解

使用EM算法求解k-means的时间复杂度是O() -->
<h2 id="调包篇"><a href="#调包篇" class="headerlink" title="调包篇"></a>调包篇</h2><p>还是以调用sklearn为例，sklearn.cluster.KMeans对应于k-means算法，此外还有sklearn.cluster.MiniBatchKMeans, 顾名思义，就是使用批梯度下降算法优化目标函数，收敛速度会比KMeans快一点，但是结果可能要稍差。</p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" target="_blank" rel="external">KMeans</a></p>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans" target="_blank" rel="external">MiniBatchKMeans</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://ljblog.org/2016/07/19/K-Means从入门到调包/" data-id="ciwgimzgl0009d8mz3uii5ego" class="article-share-link">分享到</a><div class="tags"><a href="/tags/机器学习/">机器学习</a><a href="/tags/聚类/">聚类</a></div><div class="post-nav"><a href="/2016/12/04/Java内存模型/" class="pre">Java内存模型</a><a href="/2016/07/08/Gradient-Boosting-从入门到调包-调包篇/" class="next">Gradient Boosting 从入门到调包 (调包篇)</a></div><div id="disqus_thread"><script>var disqus_shortname = 'www-ljblog-org.disqus.com';
var disqus_identifier = '2016/07/19/K-Means从入门到调包/';
var disqus_title = 'K-Means从入门到调包';
var disqus_url = 'http://ljblog.org/2016/07/19/K-Means从入门到调包/';
(function() {
  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//www-ljblog-org.disqus.com.disqus.com/count.js" async></script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/Gradient-Boosting/" style="font-size: 15px;">Gradient Boosting</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/LaTeX/" style="font-size: 15px;">LaTeX</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/聚类/" style="font-size: 15px;">聚类</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/12/08/使用pdb调试Pyton代码/">使用pdb调试Python代码</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/04/Java内存模型/">Java内存模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/19/K-Means从入门到调包/">K-Means从入门到调包</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/08/Gradient-Boosting-从入门到调包-调包篇/">Gradient Boosting 从入门到调包 (调包篇)</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/08/Gradient-Boosting-从入门到调包-入门篇/">Gradient Boosting 从入门到调包 (入门篇)</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/14/Bayesian-Nets-Graph-Model-画图工具/">Bayesian Nets/Graph Model 画图工具</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.weibo.com/basicvbvc/" title="微博" target="_blank">微博</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Yet Another Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-39855248-3','auto');ga('send','pageview');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>