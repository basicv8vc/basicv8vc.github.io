<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>NLP | Yet Another Blog</title><meta name=keywords content><meta name=description content="Hello World"><meta name=author content><link rel=canonical href=https://basicv8vc.github.io/tags/nlp/><link crossorigin=anonymous href=/assets/css/stylesheet.min.ed52a04cba0843fef8297e018b15e8a32a989ea4415133cb8bf77414d3815f7b.css integrity="sha256-7VKgTLoIQ/74KX4BixXooyqYnqRBUTPLi/d0FNOBX3s=" rel="preload stylesheet" as=style><link rel=icon href=https://basicv8vc.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://basicv8vc.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://basicv8vc.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://basicv8vc.github.io/apple-touch-icon.png><link rel=mask-icon href=https://basicv8vc.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://basicv8vc.github.io/tags/nlp/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><meta property="og:title" content="NLP"><meta property="og:description" content="Hello World"><meta property="og:type" content="website"><meta property="og:url" content="https://basicv8vc.github.io/tags/nlp/"><meta property="og:image" content="https://basicv8vc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://basicv8vc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="NLP"><meta name=twitter:description content="Hello World"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://basicv8vc.github.io/ accesskey=h title="basicv8vc (Alt + H)">basicv8vc</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://basicv8vc.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://basicv8vc.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://basicv8vc.github.io/tags/>Tags</a></div><h1>NLP</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>Hugging Face🤗 : NLP明星创业公司是如何炼成的</h2></header><div class=entry-content><p>2016年，两位法国人怀揣着对聊天机器人(chatbot)行业未来的美好向往，创立了Hugging Face 🤗，次年推出了一款和公司同名的机器人聊天App。最初，他们只是想为无聊的年轻人提供一个打发时间的地方，"Its entire purpose is to be fun" 可是不论是从技术难度还是商业模式上看，在2016年的时间点选择做开放领域的闲聊机器人，都不是一个明智选择。 时间来到了2018年10月29号，这一天公司首席科学家Thomas Wolf在GitHub上创建了一个名为pytorch-pretrained-BERT的项目，提交了第一个commit，这个项目最初的目的是如此简单，将Google基于tensorflow实现的BERT模型用pytorch进行了重写，并且可以加载Google公开的模型参数。但是，项目的火热程度超出了所有人的预期，Hugging Face也在开源模式中一路高歌猛进，顺利完成了公司转型，成为了当下NLP领域最火的创业公司（之一）。
入局聊天机器人 现在当你打开Hugging Face的官网，映入眼帘的都是"AI community"、“SOTA models”、“Open Source"等词汇，或许很多人都不知道，这曾经是一家做聊天机器人(chatbot)的公司，而且做的还是开放领域(open domain)的闲聊机器人，对，就是类似微软小冰，让我们把时间线拨回2016年。
Clem Delangue1和Julien Chaumond2一起参加了风投机构Betaworks举办的Botcamp加速器项目，专门为聊天机器人创业公司提供指导，在此期间（或者更早？）他们俩创立了Hugging Face3，研发一款为青少年打发时间找点乐子的陪聊型机器人，不论是公司名字（来自于emoji表情）还是产品，画风都既不商业(Enterprise)也不严肃，从这段时间的PR来看，他们坚信AI friend是大有未来的，We really have this vision where we think everyone will have an AI friend and everyone will discuss things every day with Hugging Face, so that’s really what we’re focused on right now and for the next few years4
左边 是CTO Julien Chaumond，右边 是CEO Clem Delangue 在2017年3月9号，他们在iOS App Store正式推出了Hugging Face App，产品的界面是这样的：...</p></div><footer class=entry-footer><span title="2022-04-21 19:09:35 +0800 CST">April 21, 2022</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to Hugging Face🤗 : NLP明星创业公司是如何炼成的" href=https://basicv8vc.github.io/posts/huggingface/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>读PyTorch源码学习RNN（1）<sup><span class=entry-isdraft>&nbsp;&nbsp;[draft]</span></sup></h2></header><div class=entry-content><p>PyTorch中RNN的实现分两个版本：1）GPU版；2）CPU版。由于GPU版是直接调用NVIDIA cuDNN的RNN API，这里咱就略去不表，CPU版最开始使用Python实现，自v1.0.0之后改为C++，为了不让语言成为理解RNN的障碍，所以本文以最后一个Python实现版本 v0.4.1为例讲述RNN模型。
RNN，更准确的说，torch.nn.RNN，实现的是Jeffrey Elman在1990年提出的simple recurrent neural network (SRNN)，它还有一个更为广泛的称呼：Elman network。
RNN的隐状态计算公式如下： $$h_t = \tanh(W_{ih} * x_t + b_{ih} + W_{hh} * h_{t-1} + b_{hh})$$
模型包含两个参数矩阵\(W_{ih}\) 、\(W_{hh}\) 以及两个bias变量\(b_{ih}\) 、\(b_{hh}\)。
原来这就是RNN呀，虽然一提到RNN，各种论文、博客都会讲到什么sequence、递归、循环，各种绕的词汇，而本质上，RNN模型只包含这四个参数，不论序列长度是多少，只有这四个参数，果然够simple~ 所谓的训练过程就是在寻找这四个参数的最优值! (注：更严谨的说法是，对于单层单方向的RNN网络，只包含这四个参数)
讲到这里，插三个小问题。
PyTorch中RNN仅支持两种激活函数：tanh和ReLU。为啥不支持sigmoid以及各种ReLU的变形呢？前面提到了，PyTorch的GPU版没有自己实现，而是直接调用了cuDNN，因为cuDNN中的RNN仅支持tanh和ReLU（cuDNN RNN Mode）。为了统一，CPU版的RNN也只支持tanh和ReLU。
很多博客在讲解RNN时，都会说“RNN每个时刻的输入是\(x_{t}\)和上一个时刻的隐状态\(h_{t-1}\)，输出是当前时刻隐状态\(h_{t}\)和模型输出\(y_{t}\)”。而实际上，从RNN的隐状态计算公式可以看到，RNN输出的只有\(h_{t}\)，根本没有所谓的\(y_{t}\)。很多人之所以这么说，其实是混淆了一个概念：在将RNN应用于具体任务时，比如情感分类，在得到RNN的隐状态后，通常并不会将\(h_{t}\)和类别label直接关联，而是在\(h_{t}\)后面接几层全连接网络，而全连接网络的输出才是\(y_{t}\)。so，还是要分清RNN的\(h_{t}\)和分类模型的\(y_{t}\)。
用过PyTorch的朋友大概都知道，对于不同的网络层，输入数据的维度虽然不同，但是通常第一维都是batch_size，比如torch.nn.Linear的输入(batch_size, *, in_features)，torch.nn.Conv2d的输入（batch_size, \(C_{in}\), \(H_{in}\), \(W_{in}\)）。而RNN的输入却是(seq_len, batch_size, input_size)，batch_size位于第二维度！虽然你可以将batch_size和序列长度seq_len对换位置，此时只需要把参数batch_first设置为True。但是默认情况下RNN输入为啥不是batch first？原因同上，因为cuDNN中RNN的API就是batch_size在第二维度！进一步，为啥cuDNN要这么做呢？举个例子，假设输入序列的长度(seq_len)是3，batch_size是2，一个batch的数据是[[“A”, “B”, “C”], [“D”, “E”, “F”]]，如图1所示。由于RNN是序列模型，只有\(t_{1}\)时刻计算完成，才能进入\(t_{2}\)时刻，而"batch"就体现在每个时刻\(t_{i}\)的计算过程中，图1中\(t_{1}\)时刻将[“A”, “D”]作为当前时刻的batch数据，\(t_{2}\)时刻将[“B”, “E”]作为当前时刻的batch数据，可想而知，“A"与"D"在内存中相邻比"A"与"B"相邻更合理，这样取数据时才更高效。而不论Tensor的维度是多少，在内存中都以一维数组的形式存储，batch first意味着Tensor在内存中存储时，先存储第一个sequence，再存储第二个… 而如果是seq_len first，模型的输入在内存中，先存储所有sequence的第一个元素，然后是第二个元素… 两种区别如图2所示，seq_len first意味着不同sequence中同一个时刻对应的输入元素(比如"A”, “D” )在内存中是毗邻的，这样可以快速读取数据。</p></div><footer class=entry-footer><span title="2017-12-19 11:12:58 +0000 +0000">December 19, 2017</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 读PyTorch源码学习RNN（1）" href=https://basicv8vc.github.io/posts/%E8%AF%BBpytorch%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0rnn-01/></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://basicv8vc.github.io/>Yet Another Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>