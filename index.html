<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.97.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Yet Another Blog</title><meta name=keywords content="Blog,Portfolio,PaperMod"><meta name=description content="Hello World"><meta name=author content><link rel=canonical href=https://basicv8vc.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.min.ed52a04cba0843fef8297e018b15e8a32a989ea4415133cb8bf77414d3815f7b.css integrity="sha256-7VKgTLoIQ/74KX4BixXooyqYnqRBUTPLi/d0FNOBX3s=" rel="preload stylesheet" as=style><link rel=icon href=https://basicv8vc.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://basicv8vc.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://basicv8vc.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://basicv8vc.github.io/apple-touch-icon.png><link rel=mask-icon href=https://basicv8vc.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://basicv8vc.github.io/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><meta property="og:title" content="Yet Another Blog"><meta property="og:description" content="Hello World"><meta property="og:type" content="website"><meta property="og:url" content="https://basicv8vc.github.io/"><meta property="og:image" content="https://basicv8vc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://basicv8vc.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Yet Another Blog"><meta name=twitter:description content="Hello World"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Yet Another Blog","url":"https://basicv8vc.github.io/","description":"Hello World","thumbnailUrl":"https://basicv8vc.github.io/favicon.ico","sameAs":["https://github.com/basicv8vc","https://www.zhihu.com/people/basicv8vc","https://twitter.com/b4s1cv8vc1"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://basicv8vc.github.io/ accesskey=h title="basicv8vc (Alt + H)">basicv8vc</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://basicv8vc.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>Hi</h1></header><div class=entry-content><p></p></div><footer class=entry-footer><div class=social-icons><a href=https://github.com/basicv8vc target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a><a href=https://www.zhihu.com/people/basicv8vc target=_blank rel="noopener noreferrer me" title=Zhihu><svg class="svg-icon" style="width:2em;height:2em;fill:currentColor;overflow:hidden" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M351.791182 562.469462h192.945407c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262h159.282726s-.86367-67.402109-18.578124-67.402109-279.979646.0-279.979646.0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461s24.62791 5.832845 36.941354.0c12.313443-5.832845 68.050885-25.924439 84.252893-103.69571h86.570681c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262H109.86113c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449H279.868105c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513.0.0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-.055259.185218 167.855986 193.263655s22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-.045025.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"/><path d="M584.918753 182.033893v668.840094h70.318532l28.807093 80.512708 121.875768-80.512708h153.600307L959.520453 182.033893h-374.6017zM887.150192 778.934538h-79.837326l-99.578949 65.782216-23.537066-65.782216h-24.855084L659.341766 256.673847h227.807403V778.934538z"/></svg></a><a href=https://twitter.com/b4s1cv8vc1 target=_blank rel="noopener noreferrer me" title=Twitter><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></div></footer></article><article class=post-entry><header class=entry-header><h2>DeepSpeed之ZeRO系列：将显存优化进行到底</h2></header><div class=entry-content><p>前言 目前训练超大规模语言模型主要有两条技术路线：TPU + XLA + TensorFlow/JAX 和 GPU + PyTorch + Megatron-LM + DeepSpeed。前者由Google主导，由于TPU和自家云平台GCP深度绑定，对于非Googler来说， 只可远观而不可把玩，后者背后则有NVIDIA、Meta、MS大厂加持，社区氛围活跃，也更受到群众欢迎。
上面提到的DeepSpeed的核心是ZeRO(Zero Redundancy Optimizer)，简单来说，它是一种显存优化的数据并行(data parallelism, DP)方案。而“优化“这个话题又永无止境，在过去两年DeepSpeed团队发表了三篇ZeRO相关的论文，提出了去除冗余参数、引入CPU和内存、引入NVMe等方法，从始至终都围绕着一个目标：将显存优化进行到底。
ZeRO: 一种去除冗余的数据并行方案 ZeRO: Memory Optimizations Toward Training Trillion Parameter Models 发表在SC 20，DeepSpeed项目最初就是论文中ZeRO方法的官方实现。
背景 如今训练大模型离不开各种分布式并行策略，常用的并行策略包括：
数据并行（data parallelism, DP）：假设有 \(N\) 张卡，每张卡都保存一个模型，每一次迭代（iteration/step）都将batch数据分割成 \(N\) 个等大小的micro-batch，每张卡根据拿到的micro-batch数据独立计算梯度，然后调用AllReduce计算梯度均值，每张卡再独立进行参数更新。 # https://huggingface.co/docs/transformers/parallelism#model-parallelism # 假设模型有三层：L0, L1, L2 # 每层有两个神经元 # 两张卡 GPU0: L0 | L1 | L2 ---|----|--- a0 | b0 | c0 a1 | b1 | c1 GPU1: L0 | L1 | L2 ---|----|--- a0 | b0 | c0 a1 | b1 | c1 模型并行（model parallelism/tensor parallelism, MP/TP）：有的tensor/layer很大，一张卡放不下，将tensor分割成多块，一张卡存一块。 # https://huggingface....</p></div><footer class=entry-footer><span title="2022-05-14 23:20:54 +0800 CST">May 14, 2022</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to DeepSpeed之ZeRO系列：将显存优化进行到底" href=https://basicv8vc.github.io/posts/zero/></a></article><article class=post-entry><header class=entry-header><h2>Hugging Face🤗 : NLP明星创业公司是如何炼成的</h2></header><div class=entry-content><p>2016年，两位法国人怀揣着对聊天机器人(chatbot)行业未来的美好向往，创立了Hugging Face 🤗，次年推出了一款和公司同名的机器人聊天App。最初，他们只是想为无聊的年轻人提供一个打发时间的地方，"Its entire purpose is to be fun" 可是不论是从技术难度还是商业模式上看，在2016年的时间点选择做开放领域的闲聊机器人，都不是一个明智选择。 时间来到了2018年10月29号，这一天公司首席科学家Thomas Wolf在GitHub上创建了一个名为pytorch-pretrained-BERT的项目，提交了第一个commit，这个项目最初的目的是如此简单，将Google基于tensorflow实现的BERT模型用pytorch进行了重写，并且可以加载Google公开的模型参数。但是，项目的火热程度超出了所有人的预期，Hugging Face也在开源模式中一路高歌猛进，顺利完成了公司转型，成为了当下NLP领域最火的创业公司（之一）。
入局聊天机器人 现在当你打开Hugging Face的官网，映入眼帘的都是"AI community"、“SOTA models”、“Open Source"等词汇，或许很多人都不知道，这曾经是一家做聊天机器人(chatbot)的公司，而且做的还是开放领域(open domain)的闲聊机器人，对，就是类似微软小冰，让我们把时间线拨回2016年。
Clem Delangue1和Julien Chaumond2一起参加了风投机构Betaworks举办的Botcamp加速器项目，专门为聊天机器人创业公司提供指导，在此期间（或者更早？）他们俩创立了Hugging Face3，研发一款为青少年打发时间找点乐子的陪聊型机器人，不论是公司名字（来自于emoji表情）还是产品，画风都既不商业(Enterprise)也不严肃，从这段时间的PR来看，他们坚信AI friend是大有未来的，We really have this vision where we think everyone will have an AI friend and everyone will discuss things every day with Hugging Face, so that’s really what we’re focused on right now and for the next few years4
左边 是CTO Julien Chaumond，右边 是CEO Clem Delangue 在2017年3月9号，他们在iOS App Store正式推出了Hugging Face App，产品的界面是这样的：...</p></div><footer class=entry-footer><span title="2022-04-21 19:09:35 +0800 CST">April 21, 2022</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to Hugging Face🤗 : NLP明星创业公司是如何炼成的" href=https://basicv8vc.github.io/posts/huggingface/></a></article><article class=post-entry><header class=entry-header><h2>K-Means从入门到调包</h2></header><div class=entry-content><p>在做数据挖掘项目时，拿到数据，首先要分析问题和观察数据，我在“观察数据”这一阶段主要是看看有没有直观的数据规律以及异常点，对于那些特征维度较低的数据，比如仅仅2维，我选择画散点图观察，高纬度数据可以用t-SNE降维后再画图。除了可视化，聚类算法也是找到异常点的常用手段之一。
这篇博客介绍一种最基本的聚类算法：K-Means。
算法描述与EM 聚类算法的作用是将数据集自动划分为多个不同的集合。 K-Means算法是典型的无监督算法，对于数据集\(D\), 我们设定参数k(k个集合)，她就能自动地学习出k个类别，简单又神奇。那么K-Means是如何学习到这k个集合呢？专业一点说就是，K-Means的目标函数是啥？如何优化她的目标函数？先回答第一个问题，下面就是K-Means的目标函数：
物理意义：我们希望找到的k个集合，每个集合内的点都距离此集合内平均值点最近(每个集合中的点都紧密团结在一起)。
知道了目标函数，下一步就要考虑如何求解，最常见的求解方法是Lloyd算法，也就是使用EM算法，注意，Lloyd算法得到的结果是局部极小值而不是全局最小值哦。
EM算法求解步骤很简单，总共分三步：
将所有数据点都分配到某个集合 -> 计算每个点到集合平均值点的欧氏距离 计算每个集合内点的平均值 -> 计算每个特征的平均值 重复上面两步直到局部收敛 -> 前后两次迭代的集合结果相同 上面的三步概括起来就是 E->M->E->M->………..
import numpy as np from collections import defaultdict from random import uniform class KMeans(object): """ kmeans 聚类算算 """ def __init__(self): pass def cluster(self, X, k, initializer="random"): self.X = X self.k = k self.centers = defaultdict(list) self.assignment = np.zeros(self.X.shape[0]) #记录每个样本属于哪个中心点 if initializer == "random": self._initialize() #初始化得到k个点 elif initializer == "kmeans++": self....</p></div><footer class=entry-footer><span title="2016-07-19 11:12:58 +0000 +0000">July 19, 2016</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to K-Means从入门到调包" href=https://basicv8vc.github.io/posts/k-means%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E8%B0%83%E5%8C%85/></a></article><article class=post-entry><header class=entry-header><h2>Gradient Boosting 从入门到调包 (调包篇)</h2></header><div class=entry-content><p>Gradient Boosting的开源实现很多，当然首选还是XGBoost。调包，就是学习API的过程，最好的学习资料就是官方文档以及demo。我这里把基本的调用罗列出来:
xgboost调包之 基础篇.ipynb
xgboost调包之 模型篇.ipynb
xgboost调包之 sklearn接口.ipynb
xgboost调包之 特征重要性可视化.ipynb
xgboost调包之 early stopping.ipynb
xgboost调包之 结合pandas.ipynb</p></div><footer class=entry-footer><span title="2016-07-09 21:36:18 +0000 +0000">July 9, 2016</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to Gradient Boosting 从入门到调包 (调包篇)" href=https://basicv8vc.github.io/posts/gradient-boosting-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E8%B0%83%E5%8C%85-%E8%B0%83%E5%8C%85%E7%AF%87/></a></article><article class=post-entry><header class=entry-header><h2>Gradient Boosting 从入门到调包 (入门篇)</h2></header><div class=entry-content><p>开篇 虽然数据挖掘算法很多，但有过实际经验的同学肯定都知道，集成方法(ensembel method)大多数情况下都是首选。集成方法和LR、SVM算法不同，她不是一个具体的模型或算法，而是一类算法的统称。集成，从其字面意思也能看出，这家伙不是单兵作战，而是依靠团队取胜。简而言之，集成方法就是通过构建并结合多个学习器来完成学习任务。这句话有两个地方需要注意，“如何构建每一个学习器”以及“如何结合多个学习器而产生预测结果”。
如果我们按照“如何构建每一个学习器”来将集成方法分类，总体可以分为两类：1) 个体学习器减存在强依赖关系、必须串行生成的序列化方法，代表方法是Boosting；2）个体学习器之间不存在强依赖关系、可同时生成的并行化方法，代表方法是Bagging。
本文要讲到的Gradient Boosting就属于Boosting方法。
由于Gradient Boosting涉及到的知识实在是很多，完全可以写成类似"Understanding Random Forest: From Theory to Practice"的博士论文，由于水平和时间的限制，本文不会涉及过多、过深的细节，而是尽量用通俗的自然语言和数学语言来解释我对Gradient Boosting的浅显理解，仅仅是入门水平:)
决策树 既然要讲Gradient Boosting，那么决策树肯定是绕不开的，虽然Boosting方法对"个体学习器"没有要求，你可以选择LR、SVM、决策树等等。但是大多数情况下我们默认都选择决策树作为个体学习器。下面简单解释决策树算法。
决策树，顾名思义，根据树结构来进行决策。这种思想是很质朴的，和我们人类做决策时的思考过程很像，比如明天出门要不要带伞啊？如果我根据天气情况来做出决定，可以记作：
if 明天下雨： 出门带伞 else: 出门不带伞 看到没有，决策过程可以用if, else来具体化，难怪有人说，决策树就是一堆if else而已。数据挖掘比赛中很多人会首先用简单的规则跑出一个结果，这实际上就是在人工构造决策树啊。
既然决策树是一种机器学习方法，我们就想知道她的学习过程是怎么样的，也就是给定训练集如果构建一颗决策树呢？通常，决策树的构建是一个递归过程:
1 输入训练集D，特征集F 2 如果D中样本全属于同一个类别C，将当前节点标记为C类叶节点，返回 3 从F中选择最优划分特征f 4 对于f的每一个值\(f_i\), 都生成一个子节点，然后对D进行划分，f值相同的样本都放到同一个子节点，并对节点进行标记，然后对于每一个新产生的子节点，进行第1步 注意：实际上对于决策树，大多数的实现方法都是基于二叉树，比如sklearn。
划分选择 决策树算法的关键是上面的第3步，即如何选择最优划分特征。如何评价一个特征是不是优秀呢？基本的原则就是看按照某一个特征生成子节点后，子节点的样本是不是都尽可能属于同一个类别，也就是子节点的纯度越高，我们就认为这个特征"好"。
为了量化子节点的纯度，前人提出了很多具体的评价方法，包括信息增益、信息增益率和基尼指数。这些评价方法大同小异，我们就以最常见的信息增益(Information Gain)为例进行解释：
假设当前节点包含的数据集为D，则数据集的熵(entropy)定义为：
其中\(|Y|\)表示类别值的取值个数。
假设某一个特征\(f\)有V个可能的取值 \(f^{1},f^{2},…,f^{V}\), 若使用特征\(f\)对\(D\)进行划分，会产生\(V\)个子节点，其中第\(v\)个子节点包含了\(D\)中所有\(f\)取值为\(f^{v}\), 记作\(D^{v}\). 按照下式计算用\(f\)对\(D\)进行划分获得的信息增益(information gain):
信息增益越大，我们就认为用\(f\)划分所获得的纯度提升越大。
下面是用信息增益来构建决策树的简单Python代码，注意，构建的是二叉树。
def uniqueCounts(X): """ 对y的取值进行计数, 用于计算节点的purity rvalue: 计数结果 """ results = {} for row in X: y = X[-1] results[y] = results....</p></div><footer class=entry-footer><span title="2016-07-08 21:36:18 +0000 +0000">July 8, 2016</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to Gradient Boosting 从入门到调包 (入门篇)" href=https://basicv8vc.github.io/posts/gradient-boosting-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E8%B0%83%E5%8C%85-%E5%85%A5%E9%97%A8%E7%AF%87/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://basicv8vc.github.io/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2022 <a href=https://basicv8vc.github.io/>Yet Another Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>